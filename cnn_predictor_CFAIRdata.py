# -*- coding: utf-8 -*-
"""Copy of CS189_HW6_NN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ceot9hn2q-6WGSmX1_ADh-RXkfYDxMpS

# CS 189 HW 6: Neural Networks
**Note:** before starting this notebook, please make a copy of it, otherwise your changes will not persist.

This part of the assignment is designed to get you familiar with how engineerings in the real world train neural network systems. It isn't designed to be difficult. In fact, everything you need to complete the assignment is available directly on the pytorch website [here](https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html). This note book will have the following components:

1. Understanding the basics of Pytorch (no deliverables)
2. Training a simple neural network on MNIST (Deliverable = training graphs)
3. Train a model on CIFAR-10 for Kaggle (Deliverable = kaggle submission and explanation of methods)

The last part of this notebook is left open for you to explore as many techniques as you want to do as well as possible on the dataset.

You will also get practice being an ML engineer by reading documentation and using it to implement models. The first section of this notebook will cover an outline of what you need to know -- we are confident that you can find the rest on your own.

Note that like all other assignments, you are free to use this notebook or not. You just need to complete the deliverables and turn in your code. If you want to run everything outside of the notebook, make sure to appropriately install pytorch to download the datasets and copy out the code for kaggle submission. If you don't want to use pytorch and instead want to use Tensorflow, feel free, but you may still need to install pytorch to download the datasets. That said, we will recommend pytorch over tensorflow since the latter has a somewhat steep learning curve and the former is more accessible to beginners.
"""

# Imports for pytorch
import numpy as np
import torch
import torchvision
import torchvision.transforms
from torch import nn
import matplotlib
from matplotlib import pyplot as plt
import tqdm

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

"""# 1. Understanding Pytorch

Pytorch is based on the "autograd" paradigm. Essentially, you perform operations on multi-dimensional arrays like in numpy, except pytorch will automatically handle gradient tracking. In this section you will understand how to use pytorch.

This section should help you understand the full pipeline of creating and training a model in pytorch. Feel free to re-use code from this section in the assigned tasks.

Content in this section closely follows this pytorch tutorial: https://pytorch.org/tutorials/beginner/basics/intro.html

## Tensors

Tensors can be created from numpy data or by using pytorch directly.
"""

data = [[1, 2],[3, 4]]
x_data = torch.tensor(data)

np_array = np.array(data)
x_np = torch.from_numpy(np_array)

shape = (2,3,)
rand_tensor = torch.rand(shape)
np_rand_array = rand_tensor.numpy()

print(f"Tensor from np: \n {x_np} \n")
print(f"Rand Tensor: \n {rand_tensor} \n")
print(f"Rand Numpy Array: \n {np_rand_array} \n")

"""They also support slicing and math operations very similar to numpy. See the examples below:"""

# Slicing
tensor = torch.ones(4, 4)
print('First row: ',tensor[0])
print('First column: ', tensor[:, 0])

# Matrix Operations
y1 = tensor @ tensor.T
y2 = tensor.matmul(tensor.T)

# Getting a single item
scalar = torch.sum(y1) # sums all elements
item = scalar.item()
print("Sum as a tensor:", scalar, ", Sum as an item:", item)

"""## Autograd
This small section shows you how pytorch computes gradients. When we create tenors, we can set `requires_grad` to be true to indicate that we are using gradients. For most of the work that you actually do, you will use the `nn` package, which automatically sets all parameter tensors to have `requires_grad=True`.
"""

# Below is an example of computing the gradient for a single data point in logistic regression using pytorch's autograd.

x = torch.ones(5)  # input tensor
y = torch.zeros(1) # label
w = torch.randn(5, 1, requires_grad=True)
b = torch.randn(1, requires_grad=True)
pred = torch.sigmoid(torch.matmul(x, w) + b)
loss = torch.nn.functional.binary_cross_entropy(pred, y)
loss.backward() # Computers gradients
print("W gradient:", w.grad)
print("b gradient:", b.grad)

# when we want to actually take an update step, we can use optimizers:
optimizer = torch.optim.SGD([w, b], lr=0.1)
print("Weight before", w)
optimizer.step() # use the computed gradients to update
# Print updated weights
print("Updated weight", w)

# Performing operations with gradients enabled is slow...
# You can disable gradient computation using the following enclosure:
with torch.no_grad():
    # Perform operations without gradients
    ...

"""## Devices
Pytorch supports accelerating computation using GPUs which are available on google colab. To use a GPU on google colab, go to runtime -> change runtime type -> select GPU.

Note that there is some level of strategy for knowing when to use which runtime type. Colab will kick users off of GPU for a certain period of time if you use it too much. Thus, its best to run simple models and prototype to get everything working on CPU, then switch the instance type over to GPU for training runs and parameter tuning.

Its best practice to make sure your code works on any device (GPU or CPU) for pytorch, but note that numpy operations can only run on the CPU. Here is a standard flow for using GPU acceleration:
"""

# Determine the device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device", device)
# Next create your tensors
tensor = torch.zeros(4, 4, requires_grad=True)
# Move the tensor to the device you want to use
tensor = tensor.to(device)

# Perform whatever operations you want.... (often this will involve gradients)
# These operations will be accelerated by GPU.
tensor = 10*(tensor + 1)

# bring the tensor back to CPU, first detaching it from any gradient computations
tensor = tensor.detach().cpu()

tensor_np = tensor.numpy() # Convert to numpy if you want to perform numpy operations.

"""## The NN Package
Pytorch implements composable blocks in `Module` classes. All layers and modules in pytorch inherit from `nn.Module`. When you make a module you need to implement two functions: `__init__(self, *args, **kwargs)` and `foward(self, *args, **kwargs)`. Modules also have some nice helper functions, namely `parameters` which will recursively return all of the parameters. Here is an example of a logistic regression model:
"""

class Perceptron(nn.Module):
  def __init__(self, in_dim):
    super().__init__()
    self.layer = nn.Linear(in_dim, 1) # This is a linear layer, it computes Xw + b

  def forward(self, x):
    return torch.sigmoid(self.layer(x)).squeeze(-1)

perceptron = Perceptron(10)
perceptron = perceptron.to(device) # Move all the perceptron's tensors to the device
print("Parameters", list(perceptron.parameters()))

"""## Datasets

Pytorch has nice interfaces for using datasets. Suppose we create a logistic regression dataset as follows:
"""

c1_x1, c1_x2 = np.random.multivariate_normal([-2.5,3], [[1, 0.3],[0.3, 1]], 100).T
c2_x1, c2_x2 = np.random.multivariate_normal([1,1], [[2, 1],[1, 2]], 100).T
c1_X = np.vstack((c1_x1, c1_x2)).T
c2_X = np.vstack((c2_x1, c2_x2)).T
train_X = np.concatenate((c1_X, c2_X))
train_y = np.concatenate((np.zeros(100), np.ones(100)))
# Shuffle the data
permutation = np.random.permutation(train_X.shape[0])
train_X = train_X[permutation, :]
train_y = train_y[permutation]
# Plot the data
plt.plot(c1_x1, c1_x2, 'x')
plt.plot(c2_x1, c2_x2, 'o')
plt.axis('equal')
plt.show()

"""We can then create a pytorch dataset object as follows. Often times, the default pytorch datasets will create these objects for you. Then, we can apply dataloaders to iterate over the dataset in batches."""

dataset = torch.utils.data.TensorDataset(torch.from_numpy(train_X), torch.from_numpy(train_y))
# We can create a dataloader that iterates over the dataset in batches.
dataloader = torch.utils.data.DataLoader(dataset, batch_size=10, shuffle=True)
for x, y in dataloader:
    print("Batch x:", x)
    print("Batch y:", y)
    break

# Clean up the dataloader as we make a new one later
del dataloader

"""## Training Loop Example
Here is an example of training a full logistic regression model in pytorch. Note the extensive use of modules -- modules can be used for storing networks, computation steps etc.
"""

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print("Using device", device)

epochs = 10
batch_size = 10
learning_rate = 0.01

num_features = dataset[0][0].shape[0]
model = Perceptron(num_features).to(device)
optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)
criterion = torch.nn.BCELoss()
dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)
model.train() # Put model in training mode
for epoch in range(epochs):
    training_losses = []
    for x, y in tqdm.notebook.tqdm(dataloader, unit="batch"):
        #print(x, y)
        x, y = x.float().to(device), y.float().to(device)
        optimizer.zero_grad() # Remove the gradients from the previous step
        pred = model(x)
        loss = criterion(pred, y)
        loss.backward()
        optimizer.step()
        training_losses.append(loss.item())
    print("Finished Epoch", epoch + 1, ", training loss:", np.mean(training_losses))

# We can run predictions on the data to determine the final accuracy.
with torch.no_grad():
    model.eval() # Put model in eval mode
    num_correct = 0
    for x, y in dataloader:
        x, y = x.float().to(device), y.float().to(device)
        pred = model(x)
        num_correct += torch.sum(torch.round(pred) == y).item()
    print("Final Accuracy:", num_correct / len(dataset))
    model.train() # Put model back in train mode

"""# Task 1: MLP For FashionMNIST
Earlier in this course you trained SVMs and GDA models on MNIST. Now you will train a multi-layer perceptron model on an MNIST-like dataset. Your deliverables are as follows:

1. Code for training an MLP on MNIST (can be in code appendix, tagged in your submission).
2. A plot of the training loss and validation loss for each epoch of training after trainnig for at least 8 epochs.
3. A plot of the training and validation accuracy, showing that it is at least 82% for validation by the end of training.

Below we will create the training and validation datasets for you, and provide a very basic skeleton of the code. Please leverage the example training loop from above.

Some pytorch components you should definitely use:
1. `nn.Linear`
2. Some activation function like `nn.ReLU`
3. `nn.CrossEntropyLoss`: if you choose to use `nn.CrossEntropyLoss` or `F.cross_entropy`, DO NOT add an explicit softmax layer in your neural network. PyTorch devs found it more numerically stable to combine softmax and cross entropy loss into a single module and if you explicitly attach a softmax layer at the end of your model, you would unintentionally be applying it twice, which can degrade performance.

Here are challenges you will need to overcome:
1. The data is default configured in image form i.e. (1 x 28 x 28), versus one feature vector. You will need to reshape it somewhere to feed it in as vector to the MLP. There are many ways of doing this.
2. You need to write code for plotting.
3. You need to find appropriate hyper-parameters to achieve good accuracy.

Your underlying model must be fully connected or dense, and may not have convolutions etc., but you can use anything in torch.optim or any layers in torch.nn besides nn.Linear that do not have weights.

Before training a neural network, let's visualize our data first! Running the cell below will display the first 9 images in a 3 by 3 grid.
"""

# images = [training_data[i][0] for i in range(9)]
# plt.imshow(torchvision.utils.make_grid(torch.stack(images), nrow=3, padding=5).numpy().transpose((1, 2, 0)))

# Feedfoward Neural Network with 5 hidden layers
class FFNN(nn.Module):
    def __init__(self, input_dim, output_dim):
        super().__init__()

        h1_dim=784
        h2_dim=588 # 75%
        h3_dim=392 # 50%
        h4_dim=196 # 25%
        h5_dim=98  # 196/2

        self.linear = torch.nn.Linear(input_dim, h1_dim)
        self.fc1_2 = torch.nn.Linear(h1_dim, h2_dim)
        self.fc2_3 = torch.nn.Linear(h2_dim, h3_dim)
        self.fc3_4 = torch.nn.Linear(h3_dim, h4_dim)
        self.fc4_5 = torch.nn.Linear(h4_dim, h5_dim)
        self.fc5_6 = torch.nn.Linear(h5_dim, h5_dim)
        self.fc6_output = torch.nn.Linear(h5_dim, output_dim)

        self.relu = torch.nn.ReLU()

    def forward(self, input):
        h1=self.linear(input)
        h2=self.relu(h1)

        h3=self.fc1_2(h2)
        h4=self.relu(h3)

        h5=self.fc2_3(h4)
        h6=self.relu(h5)

        h7=self.fc3_4(h6)
        h8=self.relu(h7)

        h9=self.fc4_5(h8)
        h10=self.relu(h9)

        h11=self.fc5_6(h10)
        h12=self.relu(h11)

        h13=self.fc6_output(h12)
        #h14=self.relu(h13)


        return h13

from torchvision import transforms
# https://saturncloud.io/blog/how-to-normalize-image-dataset-using-pytorch/

def get_mean_std(loader):
    # Compute the mean and standard deviation of all pixels in the dataset
    num_pixels = 0
    mean = 0.0
    std = 0.0
    for images, _ in loader:
        batch_size, num_channels, height, width = images.shape
        num_pixels += batch_size * height * width
        mean += images.mean(axis=(0, 2, 3)).sum()
        std += images.std(axis=(0, 2, 3)).sum()

    mean /= num_pixels
    std /= num_pixels

    return mean, std

batch_size = 10

# prep training data
transform = torchvision.transforms.ToTensor() # feel free to modify this as you see fit.

training_data = torchvision.datasets.FashionMNIST(
    root="data",
    train=True,
    download=True,
    transform=transform,
)

training_loader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)

mean, std = get_mean_std(training_loader)

data_transforms = transforms.Compose([
transforms.ToTensor(),
transforms.Normalize(mean=mean, std=std)
])

training_data = torchvision.datasets.FashionMNIST(
root="data",
train=True,
download=True,
transform=data_transforms,
)

training_loader = torch.utils.data.DataLoader(training_data, batch_size=batch_size, shuffle=True)

batch_size = 10

# prep validation datа

transform = torchvision.transforms.ToTensor() # feel free to modify this as you see fit.

validation_data = torchvision.datasets.FashionMNIST(
    root="data",
    train=False,
    download=True,
    transform=transform,
)

validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size, shuffle=False)

mean_val, std_val = get_mean_std(validation_loader)

data_transforms_val = transforms.Compose([
transforms.ToTensor(),
transforms.Normalize(mean=mean_val, std=std_val)
])

validation_data = torchvision.datasets.FashionMNIST(
root="data",
train=False,
download=True,
transform=data_transforms_val,
)

validation_loader = torch.utils.data.DataLoader(validation_data, batch_size=batch_size, shuffle=False)

# evaluation function: (only for the FFNN)
def evaluation(classifier, dataloader, validation=True):
    cross_entropy=nn.CrossEntropyLoss()
    classifier.eval() # Put model in eval mode
    corr=0.
    total=0.

    val_losses = []
    with torch.no_grad():


      for x, y in dataloader: #This is all I change right? validation_loader
          x = x.reshape(batch_size, 1, 784)
          x, y = x.to(device), y.to(device)
          y_preds = classifier.forward(x)

          if validation == True:
          # get validation loss
              loss=cross_entropy(y_preds.view(-1, num_labels), y.view(-1))
              val_losses.append(loss.item())


          for idx, y_pred in enumerate(y_preds):

                prediction = torch.argmax(y_pred)
                prediction_num = prediction.item()
                if prediction_num == y[idx]:
                    corr += 1.
                total += 1

    mean_val_loss = np.mean(val_losses)
    final_accuracy = corr/total
    classifier.train()
    return final_accuracy, mean_val_loss

ffnn_classifier=FFNN(784, 10).to(device)
optimizer=torch.optim.Adam(ffnn_classifier.parameters(), lr=0.001, weight_decay=0)
cross_entropy=nn.CrossEntropyLoss()

num_labels=10
epochs=10

val_accs = []
train_accs = []

mean_train_losses=[]
mean_val_losses=[]

for epoch in range(epochs):
    ffnn_classifier.train()
    training_losses=[]


    # training our model
    for x, y in training_loader:
        x = x.reshape(batch_size, 1, 784)
        x, y = x.to(device), y.to(device)
        optimizer.zero_grad()
        y_pred = ffnn_classifier.forward(x)
        loss=cross_entropy(y_pred.view(-1, num_labels), y.view(-1))
        loss.backward()
        optimizer.step()
        training_losses.append(loss.item())

    mean_train_loss = np.mean(training_losses)

    print("Finished Epoch", epoch + 1, ", training loss:", mean_train_loss)
    #print(f"\n\n validation loss: {mean_val_loss}")

    val_accuracy, mean_val_loss = evaluation(ffnn_classifier, validation_loader)
    train_accuracy, dummie_var = evaluation(ffnn_classifier, training_loader, validation=False)

    mean_train_losses.append(mean_train_loss)
    mean_val_losses.append(mean_val_loss)

    val_accs.append(val_accuracy)
    train_accs.append(train_accuracy)
    print("Training Accuracy:", train_accuracy, ", training loss:", mean_train_loss)
    print("Validation Accuracy:", val_accuracy, ", validation loss:", mean_val_loss)

"""# Traning Loss and Validation Loss vs.\ Epochs

A plot of the training loss and validation loss for each epoch of training after trainnig for at least 8 epochs.
"""

epochs = np.arange(1, 10)
epochs

len(mean_train_losses[:9])

plt.plot(epochs, mean_train_losses[:9], label="Training Loss")
plt.plot(epochs, mean_val_losses[:9], label="Validation Loss")

plt.title("Number of Epochs vs Loss")
plt.legend(["Training Loss", "Validation Loss"])
plt.xlabel("Number of Epochs")
plt.ylabel("Cross Entropy Loss")
#plt.legend()

"""A plot of the training and validation accuracy, showing that it is at least 82% for validation by the end of training."""

plt.plot(epochs, train_accs[:9], label="Training Accuracy")
plt.plot(epochs, val_accs[:9], label="Validation Loss")

plt.title("Number of Epochs vs Accuracy")
plt.legend(["Training Accuracy", "Validation Accuracy"])
plt.xlabel("Number of Epochs")
plt.ylabel("Accuracy")

"""# Task 2: CNNs for CIFAR-10

In this section, you will create a CNN for the CIFAR dataset, and submit your predictions to Kaggle. It is recommended that you use GPU acceleration for this part.

Here are some of the components you should consider using:
1. `nn.Conv2d`
2. `nn.ReLU`
3. `nn.Linear`
3. `nn.CrossEntropyLoss`: if you choose to use `nn.CrossEntropyLoss` or `F.cross_entropy`, DO NOT add an explicit softmax layer in your neural network. PyTorch devs found it more numerically stable to combine softmax and cross entropy loss into a single module and if you explicitly attach a softmax layer at the end of your model, you would unintentionally be applying it twice, which can degrade performance.
5. `nn.MaxPooling2d` (though many implementations without it exist; for example, you can also do strided convolutions instead of a pooling layer!)

We encourage you to explore different ways of improving your model to get higher accuracy. Here are some suggestions for things to look into:
1. CNN architectures: AlexNet, VGG, ResNets, etc.
2. Different optimizers and their parameters (see torch.optim)
3. Image preprocessing / data augmentation (see torchvision.transforms)
4. Regularization or dropout (see torch.optim and torch.nn respectively)
5. Learning rate scheduling: https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate
6. Weight initialization: https://pytorch.org/docs/stable/nn.init.html

Though we encourage you to explore, there are some rules:
1. You are not allowed to install or use packages not included by default in the Colab Environment.
2. You are not allowed to use any pre-defined architectures or feature extractors in your network.
3. You are not allowed to use **any** pretrained weights, ie no transfer learning.
4. You cannot train on the test data.

Otherwise everything is fair game.

Your deliverables are as follows:
1. Submit to Kaggle and include your test accuracy in your report.
2. Provide at least (1) training curve for your model, depicting loss per epoch or step after training for at least 8 epochs.
3. Explain the components of your final model, and how you think your design choices contributed to it's performance.

After you write your code, we have included skeleton code that should be used to submit predictions to Kaggle. **You must follow the instructions below under the submission header**. Note that if you apply any processing or transformations to the data, you will need to do the same to the test data otherwise you will likely achieve very low accuracy.

It is expected that this task will take a while to train. Our simple solution achieves a training accuracy of 90.2% and a test accuracy of 74.8% after 10 epochs (be careful of overfitting!). This easily beats the best SVM based CIFAR10 model submitted to the HW 1 Kaggle! It is possible to achieve 95% or higher test accuracy on CIFAR 10 with good model design and tuning.
"""

# Creating the datasets

transform = torchvision.transforms.Compose([
    torchvision.transforms.ToTensor(),
    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

training_data_cfair = torchvision.datasets.CIFAR10(
    root="data",
    train=True,
    download=True,
    transform=transform,
)

val_cfair = torchvision.datasets.CIFAR10(
    root="data",
    train=False,
    download=True,
    transform=transform
)

dataloader_cfair = torch.utils.data.DataLoader(training_data_cfair, batch_size=32, shuffle=True)
val_dataloader_cfair = torch.utils.data.DataLoader(val_cfair, batch_size=32)

"""Again, let's first visualize our data."""

# images = [training_data[i][0] for i in range(9)]
# plt.imshow(torchvision.utils.make_grid(torch.stack(images), nrow=3, padding=5).numpy().transpose((1, 2, 0)))

def evaluate_CNN(classifier, dataloader):
    acc_list = []
    val_losses = []
    classifier.eval()
    with torch.no_grad():
        for x, y in dataloader:
            x, y = x.to(device), y.to(device)
            out = classifier(x) # (N, 10)
            y_pred = torch.argmax(out)

            loss=cross_entropy(out, y)
            val_losses.append(loss.item())

            acc = torch.sum(y == y_pred).item() / y.shape[0]
            acc_list.append(acc)

    classifier.train()
    return np.mean(acc_list), np.mean(val_losses)

class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        # convolutional layer
        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)
        self.conv2 = nn.Conv2d(16, 32, 3, padding=1)
        self.conv3 = nn.Conv2d(32, 64, 3, padding=1)
        # max pooling layer
        self.pool = nn.MaxPool2d(2, 2)
        # fully connected layers
        self.h1 = nn.Linear(64 * 4 * 4, 512)
        self.h2 = nn.Linear(512, 64)
        self.h3 = nn.Linear(64, 10)
        # batching layers
        self.batch1 = nn.BatchNorm2d(32)
        self.batch2 = nn.BatchNorm2d(64)
        # dropout
        self.dropout = nn.Dropout(p=.5)
        # activation function
        self.relu = nn.ReLU()

    def forward(self, x):
        x = self.conv1(x)
        x = self.pool(x)
        x = self.conv2(x)
        x = self.batch1(x) #nn.BatchNorm2d(32)
        x = self.relu(x)
        x = self.pool(x)
        x = self.conv3(x)
        x = self.batch2(x)
        x = self.relu(x)
        x = self.pool(x)
        # reshaping
        x = x.view(-1, 64 * 4 * 4)
        # linear layers
        x = self.h1(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.h2(x)
        x = self.relu(x)
        x = self.dropout(x)
        x = self.h3(x)

        return x

# CFAIR classifier training and evaluation
classifier=CNN().to(device)
optimizer=torch.optim.Adam(classifier.parameters(), lr=0.001, weight_decay=0) #lr=0.001, weight_decay=0
cross_entropy=nn.CrossEntropyLoss()

num_labels=10
epochs = 10
mean_training_losses = []
mean_val_losses = []
mean_val_losses = []

for epoch in range(epochs):
    classifier.train()
    training_losses=[]

    # training our model
    train_acc_list = []
    for x, y in tqdm.notebook.tqdm(dataloader_cfair, unit="batch"):
        x, y = x.to(device), y.to(device)
        optimizer.zero_grad()
        out = classifier(x)
        loss=cross_entropy(out, y)
        loss.backward()
        optimizer.step()
        training_losses.append(loss.item())
        y_pred = torch.argmax(out, dim=-1)
        train_acc_list.append(torch.sum(y_pred == y).item() / y.shape[0])

    mean_train_l = np.mean(training_losses)
    mean_training_losses.append(mean_train_l)
    print("Finished Epoch", epoch + 1, ", training loss:", mean_train_l)
    print(f"Training Accuracy is {np.mean(train_acc_list)}")
    val_accuracy, mean_val_l = evaluate_CNN(classifier, val_dataloader_cfair)

    mean_val_losses.append(mean_val_l)
    print(f"Validation Accuracy is {val_accuracy}")

"""## GRAPH

Provide at least (1) training curve for your model, depicting loss per epoch or step after training for at least 8 epochs.
"""

epochs = np.arange(1, 11)
plt.plot(epochs, mean_training_losses, label="Training Loss")
plt.plot(epochs, mean_val_losses, label="Validation Loss")

plt.title("Number of Epochs vs Loss")
plt.legend(["Training Loss", "Validation Loss"])
plt.xlabel("Number of Epochs")
plt.ylabel("Cross Entropy Loss")

mean_training_losses

"""### Kaggle Submission
The following code is for you to make your submission to kaggle. Here are the steps you must follow:

1. Upload `cifar_test_data_sp24.npy` to the colab notebook by going to files on the left hand pane, then hitting "upload". This file may take roughly a minute to upload and you should not proceed to the following steps until it has completely finished uploading (students in the past have run into issues where they were accidentally testing on a partially uploaded test set and getting garbage results).
2. Run the following cell to generate the dataset object for the test data. Feel free to modify the code to use the same transforms that you use for the training data. By default, this will re-use the `transform` variable.
3. In the second cell, write code to run predictions on the testing dataset and store them into an array called `predictions`.
4. Run the final cell which will convert your predictions array into a CSV for kaggle.
5. Go to the files pane again, and download the file called `submission.csv` by clicking the three dots and then download.

"""

from PIL import Image
import os

class CIFAR10Test(torchvision.datasets.VisionDataset):

    def __init__(self, transform=None, target_transform=None):
        super(CIFAR10Test, self).__init__(None, transform=transform,
                                      target_transform=target_transform)
        assert os.path.exists("/cifar10_test_data_sp24.npy"), "You must upload the test data to the file system."
        self.data = [np.load("/cifar10_test_data_sp24.npy", allow_pickle=False)]

        self.data = np.vstack(self.data).reshape(-1, 3, 32, 32)
        self.data = self.data.transpose((0, 2, 3, 1))  # convert to HWC

    def __getitem__(self, index: int):
        img = self.data[index]
        img = Image.fromarray(img)
        if self.transform is not None:
            img = self.transform(img)
        return img

    def __len__(self) -> int:
        return len(self.data)

# Create the test dataset
transform = torchvision.transforms.Compose([
    torchvision.transforms.ToTensor(),
    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))
    ])

testing_data = CIFAR10Test(
    transform=transform, # NOTE: Make sure transform is the same as used in the training dataset.
)

test_dataloader = torch.utils.data.DataLoader(testing_data, batch_size=1, shuffle=False)
predictions_list = []


classifier.eval()
with torch.no_grad():

    for x in test_dataloader:
        x = x.to(device)
        out = classifier(x) # (N, 10)
        y_pred = torch.argmax(out,-1)
        predictions_list.append(y_pred.item())

predictions = np.array(predictions_list)

len(predictions_list), testing_data.data.shape

# This code below will generate kaggle_predictions.csv file. Please download it and submit to kaggle.
import pandas as pd

if isinstance(predictions, np.ndarray):
    predictions = predictions.astype(int)
else:
    predictions = np.array(predictions, dtype=int)
assert predictions.shape == (len(testing_data),), "Predictions were not the correct shape"
df = pd.DataFrame({'Category': predictions})
df.index += 1  # Ensures that the index starts at 1.
df.to_csv('submission.csv', index_label='Id')

# Now download the submission.csv file to submit.

"""Congrats! You made it to the end."""